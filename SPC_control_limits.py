#This python script calculates the control limits for a dataset
#Ideally it is not required to fix anything in this file (if the setup is the same as proposed by Van Acht et al.)
#When running this script, input of you will be asked. Since the control limits are not required to be updated too often.

# DISCLAIMER:
#
# This code is provided "as-is".
# The author is not responsible for any errors, damages, or consequences that arise from the use of
# this code. It is the user's responsibility to thoroughly validate and test the code before using it
# in any medical or clinical environment. Ensure that all necessary precautions are taken and that
# the code complies with all applicable regulations and standards.
#
# Use at your own risk.

#Carefully read the Read Me to ensure save and more easy employement of the script

import scipy
import numpy as np
import os
import json

#Data should be saved as Data_folder --> Day_folder (YYYYMMDD) --> Patient_Folder (PID) --> scores.npy for this to work

#This file works only with scores.npy files generated by CQA_DLS.py. The .npy files, when loaded contain the following data:
#Scores[i] will give you the saved data for that ROI, present in the DLS and CS RTstruct, and not excluded by Exclusion_ROIs.csv
#Scores[i][0]: Name given to that ROI (string)
#Scores[i][1]: Date that ROI is saved (string)
#Scores[i][2]: Abbreviations of executing RTT and RO, used for potential future research (string)
#Scores[i][3]: VDSC between DLS and CS (string)
#Scores[i][4]: SDSC between DLS and CS (string)
#Scores[i][5]: HD95 between DLS and CS (string)
#Scores[i][6]: APL between DLS and CS (string)

def check_day_folder_format(day_string=''):
    """
    Function that checks whether the folders in data_path are folders in the day format and thus contain patient or are different type of folders.

    Input: 
    - day_string: string that is the name of a folder

    Output: True or False, depending on the format of the folder. It should be in the YYYYMMDD format. In other words of length 8 and represnting an integer.
    """
    if len(day_string)==8 and day_string.isdigit():
        return True
    else:
        return False

def get_data(data_path='',start_date=20240828,end_date=20250301):
    """
    Function that returns the data saved in scores.npy files.

    Input:
    - data_path: string that refers to the folder containing all the day folders
    - start_date: integer that refers to the starting point of the data that needs to be gathered
    - end_data: integer that refers to the end point of the data that needs to be gathered

    Output:
    - ROIs: list of strings of all the unique ROIs that appear in the scores.npy files
    - vdsc: list with all the VDSCs. vdsc[i] correspond to the VDSC of ROIs[i]
    - sdsc: list with all the SDSCs. vdsc[i] correspond to the SDSC of ROIs[i]
    - hd95: list with all the HD95s. vdsc[i] correspond to the HD95 of ROIs[i]
    - apl: list with all the APLs. vdsc[i] correspond to the APL of ROIs[i]
    """

    #Get all unique ROIs available in the score files 
    ROIs = []

    #Go through all the Day folders in data path
    for day in os.listdir(data_path):
        #check if the day folder should be included
        if check_day_folder_format(day) and int(day)>=start_date and int(day)<end_date:
            day_path = os.path.join(data_path,day)
            #Go through all the patients in this day folder
            for patient in os.listdir(day_path):
                patient_path = os.path.join(day_path,patient)
                #check if there is a score file available for that patient
                for file in os.listdir(patient_path):
                    if 'scores' in file:
                        score = np.load(os.path.join(patient_path,file))
                        for OAR in score:
                            #check if this score file has a new unique ROI, if so append it to the ROI list
                            if OAR[0] not in ROIs:
                                ROIs.append(OAR[0])

    #get all the scores in a big list

    #Create empty lists to save the data in per ROI
    vdsc = [[] for _ in range(len(ROIs))]
    sdsc = [[] for _ in range(len(ROIs))]
    hd95 = [[] for _ in range(len(ROIs))]
    apl = [[] for _ in range(len(ROIs))]
    #Go through all the day folders in data path
    for day in os.listdir(data_path):
        #check if the day folder should be included
        if check_day_folder_format(day) and int(day)>=start_date and int(day)<end_date:
            day_path = os.path.join(data_path,day)
            #Go through all the patients in this day folder
            for patient in os.listdir(day_path):
                patient_path = os.path.join(day_path,patient)
                #check if there is a score file available for that patient
                for file in os.listdir(patient_path):
                    if 'scores' in file:
                        score = np.load(os.path.join(patient_path,file))
                        for OAR in score:
                            #Get the data per ROI in the correct list and add the new value
                            index = ROIs.index(OAR[0])
                            vdsc[index].append(float(OAR[3]))
                            sdsc[index].append(float(OAR[4]))
                            hd95[index].append(float(OAR[5]))
                            apl[index].append(float(OAR[6]))
    return ROIs,vdsc,sdsc,hd95,apl

def calculate_control_limits(roi_vdsc=[],roi_sdsc=[],roi_hd95=[],roi_apl=[]):
    """"
    Function that generates the specification limits in a dictionary.
    1. Check if ROI is normally distributed for that metric.
    2a. If normally distributed: Target is mean, LCL = Target - 2 std, UCL = Target + 2 std
    2b. If not normally distributed: Target is median, LCL = 2.28% % boundary, UCL = 97.72% boundary, the same percentile as 2 std covers in normal distributions

    If 2 is a value that can never be reached f.e. not within 0 and 1 for dsc, set it to boundary.

    Input:
    - roi_vdsc: a list with float values for a specific roi. Received from get_data's vdsc[i]
    - roi_sdsc: a list with float values for a specific roi. Received from get_data's sdsc[i]
    - roi_hd95: a list with float values for a specific roi. Received from get_data's hd95[i]
    - roi_apl: a list with float values for a specific roi. Received from get_data's apl[i]

    Output:
    - roi_dict: a dictionary with the control limits for every metric. roi_dict['vdsc','sdsc','hd95','apl']['target','lcl','ucl'] = float
    """
    #Check for normal distribution
    if round(scipy.stats.shapiro(roi_vdsc).pvalue,5) >= 0.05:
        #roi_vdsc is normally distributted, then 2a
        vdsc_target = np.mean(roi_vdsc)
        vdsc_std = np.std(roi_vdsc)
        #VDSC LCL can not be below 0.0, so set to 0.0
        vdsc_lcl = vdsc_target-2*vdsc_std
        if vdsc_lcl <=0.0:
            vdsc_lcl = 0.0
        #VDSC UCL can not be above 1.0, so set to 1.0
        vdsc_ucl = vdsc_target+2*vdsc_std
        if vdsc_ucl >=1.0:
            vdsc_ucl = 1.0
    else:
        #roi_sdsc not normally distributed, then 2b
        vdsc_target = np.median(roi_vdsc)
        #No need to check, since percentile values are never outside VDSC limits
        vdsc_lcl = np.percentile(roi_vdsc,2.28)
        vdsc_ucl = np.percentile(roi_vdsc,97.72)
    #Save in the vdsc_dict
    vdsc_dict = {
        'target' : vdsc_target,
        'lcl' : vdsc_lcl,
        'ucl' : vdsc_ucl,
    }

    #Check for normal distribution
    if round(scipy.stats.shapiro(roi_sdsc).pvalue,5) >= 0.05:
        #roi_sdsc is normally distributted, then 2a
        sdsc_target = np.mean(roi_sdsc)
        sdsc_std = np.std(roi_sdsc)
        #SDSC LCL can not be below 0.0, so set to 0.0
        sdsc_lcl = sdsc_target-2*sdsc_std
        if sdsc_lcl <=0.0:
            sdsc_lcl = 0.0
        #SDSC UCL can not be above 1.0, so set to 1.0
        sdsc_ucl = sdsc_target+2*sdsc_std
        if sdsc_ucl >=1.0:
            sdsc_ucl = 1.0
    else:
        #roi_sdsc not normally distributed, then 2b
        sdsc_target = np.median(roi_sdsc)
        #No need to check, since percentile values are never outside SDSC limits
        sdsc_lcl = np.percentile(roi_sdsc,2.28)
        sdsc_ucl = np.percentile(roi_sdsc,97.72)
    #Save in the sdsc_dict
    sdsc_dict = {
        'target' : sdsc_target,
        'lcl' : sdsc_lcl,
        'ucl' : sdsc_ucl,
    }

    #Check for normal distribution
    if round(scipy.stats.shapiro(roi_hd95).pvalue,5) >= 0.05:
        #roi_hd95 is normally distributted, then 2a
        hd95_target = np.mean(roi_hd95)
        hd95_std = np.std(roi_hd95)
        #HD95 can not be below 0.0, so set to 0.0 if so
        hd95_lcl = hd95_target-2*hd95_std
        if hd95_lcl <=0.0:
            hd95_lcl = 0.0
        #No need to check since always above 0.0
        hd95_ucl = hd95_target+2*hd95_std

    else:
        #roi_hd95 not normally distributed, then 2b
        hd95_target = np.median(roi_hd95)
        #No need to check
        hd95_lcl = np.percentile(roi_hd95,2.28)
        hd95_ucl = np.percentile(roi_hd95,97.72)

    #Save in hd95_dict
    hd95_dict = {
        'target' : hd95_target,
        'lcl' : hd95_lcl,
        'ucl' : hd95_ucl,
    }
    #Check for normal distribution
    if round(scipy.stats.shapiro(roi_apl).pvalue,5) >= 0.05:
        #roi_slices is normally distributted, then 2a
        apl_target = np.mean(roi_apl)
        apl_std = np.std(roi_apl)
        #APL can not be below 0.0, so if so set to 0.0
        apl_lcl = apl_target-2*apl_std
        if apl_lcl <=0.0:
            apl_lcl = 0.0
        #No need to check UCL
        apl_ucl = apl_target+2*apl_std
    else:
        #roi_slices not normally distributed, then 2b
        apl_target = np.median(roi_apl)
        #No need to check percentiles
        apl_lcl = np.percentile(roi_apl,2.28)
        apl_ucl = np.percentile(roi_apl,97.72)

    #save in apl_dict
    apl_dict = {
        'target' : apl_target,
        'lcl' : apl_lcl,
        'ucl' : apl_ucl,
    }

    #Combine the dict for all 4 metrics in one roi_dict
    roi_dict = {
        'vdsc' : vdsc_dict,
        'sdsc' : sdsc_dict,
        'hd95' : hd95_dict,
        'apl' : apl_dict
    }
    return roi_dict

def get_control_limits(N_min=10,ROIs=[],vdsc=[],sdsc=[],hd95=[],apl=[],save=False,save_path='',save_name=''):
    """
    Function that gathers all the contol limits per ROI and saves them in one dictionary.

    Input:
    - N_min: integer that sets the minimum amount of times the ROI should be present before a control limit is determined. Set at 10 since this is the size of the commissioning dataset.
    - ROIs: List of unique ROIs. Output of get_data()
    - vdsc: List of vdsc floats. Output of get_data()
    - sdsc: List of sdsc floats. Output of get_data()
    - hd95: List of hd95 floats. Output of get_data()
    - apl: List of apl floats. Output of get_data()
    - save: False or True. Determines whether the control limits are saved
    - save_path: string that represents the path to the folder where the control limits will be saved to
    - save_name: string that represents the name of the control limits file. Should en with .json
    """

    #Check that if save==True that the file can be saved before going to calc the control limits
    if save and '.json' not in save_name:
        print("save_name does not end with .json")
    
    else:
        #Create an empty dictionary to save all the roi_dicts in 
        control_limits = {}
        for i, roi in enumerate(ROIs):
            #Check if the minimum ammount of data is available
            if len(vdsc[i])>N_min:
                #Determine the roi_contorl_limits
                roi_control_limits = calculate_control_limits(vdsc[i],sdsc[i],hd95[i],apl[i])
                #Add the roi_control_limits dictionary to the control_limits dictionary
                control_limits[roi] = roi_control_limits
    
        if save:
            # Save dictionary to a JSON file
            if not save_path:
                with open(save_name, 'w') as file:
                        json.dump(control_limits, file)
                print(f'control limits saved at {save_name}')
            else:
                with open(os.path.join(save_path,save_name), 'w') as file:
                    json.dump(control_limits, file)
                print(f'control limits saved at {os.path.join(save_path,save_name)}')
                
        return control_limits
    
# Prompt the user for input values
data_path = input("Enter the path to the data folder as string: ").strip()
start_date = int(input("Enter the start date (YYYYMMDD) as integer: ").strip())
end_date = int(input("Enter the end date (YYYYMMDD) as integer: ").strip())
N_min = int(input("Enter the minimum number of patients required as integer: ").strip())

# Prompt for save option
save_input = input("Do you want to save the output? (yes/no): ").strip().lower()
save = save_input in ['yes', 'y', 'true', '1']

# If saving, ask for save path and name
if save:
    save_path = input("Enter the folder path to save the output as string (if in same folder as .py script press Enter): ").strip()
    save_name = input("Enter the name for the saved file as string (without extension): ").strip()
else:
    save_path = ""
    save_name = ""

ROIs, vdsc,sdsc,hd95,apl = get_data(data_path=data_path,start_date=start_date,end_date=end_date)
control_limits = get_control_limits(N_min=N_min,ROIs=ROIs,vdsc=vdsc,sdsc=sdsc,hd95=hd95,apl=apl,save=save,save_path=save_path,save_name=f'{save_name}.json')